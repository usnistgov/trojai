

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>object-detection-feb2023 &mdash; TrojAI 1.0.0 documentation</title>
  

  
  <link rel="stylesheet" href="static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://pages.nist.gov/nist-header-footer/css/nist-combined.css" type="text/css" />

  
  
    <link rel="shortcut icon" href="static/favicon.ico"/>
  
  
  

  
  <!--[if lt IE 9]>
    <script src="static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="static/documentation_options.js"></script>
        <script src="static/jquery.js"></script>
        <script src="static/underscore.js"></script>
        <script src="static/doctools.js"></script>
        <script src="static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="static/js/theme.js"></script>

    
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
 
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-161627994-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-161627994-1');
</script>


</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> TrojAI
          

          
            
            <img src="static/trojai_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">What Is TrojAI</a></li>
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="architecture.html">System Architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="accounts.html">Accounts</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="submission.html">Submission</a></li>
<li class="toctree-l1"><a class="reference internal" href="results.html">Results</a></li>
<li class="toctree-l1"><a class="reference internal" href="software.html">Software</a></li>
<li class="toctree-l1"><a class="reference internal" href="license.html">License</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TrojAI</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          <header class="nist-header" id="nist-header" role="banner">

  <a href="https://www.nist.gov/" title="National Institute of Standards and Technology" class="nist-header__logo-link" rel="home">
    <svg aria-hidden="true" class="nist-header__logo-icon" version="1.1" xmlns="http://www.w3.org/2000/svg" width="24" height="32" viewBox="0 0 24 32">
      <path d="M20.911 5.375l-9.482 9.482 9.482 9.482c0.446 0.446 0.446 1.161 0 1.607l-2.964 2.964c-0.446 0.446-1.161 0.446-1.607 0l-13.25-13.25c-0.446-0.446-0.446-1.161 0-1.607l13.25-13.25c0.446-0.446 1.161-0.446 1.607 0l2.964 2.964c0.446 0.446 0.446 1.161 0 1.607z"></path>
    </svg>
    <svg class="nist-header__logo-image" version="1.1" xmlns="http://www.w3.org/2000/svg" viewBox="-237 385.7 109.7 29.3">
      <title>National Institute of Standards and Technology</title>
      <g>
        <path class="st0" d="M-231,415h-6v-23.1c0,0,0-4.4,4.4-5.8c4-1.3,6.6,1.3,6.6,1.3l19.7,21.3c1,0.6,1.4,0,1.4-0.6v-22h6.1V409
          c0,1.9-1.6,4.4-4,5.3c-2.4,0.9-4.9,0.9-7.9-1.7l-18.5-20c-0.5-0.5-1.8-0.6-1.8,0.4L-231,415L-231,415z"/>
        <path class="st0" d="M-195,386.1h6.1v20.7c0,2.2,1.9,2.2,3.6,2.2h26.8c1.1,0,2.4-1.3,2.4-2.7c0-1.4-1.3-2.8-2.5-2.8H-176
          c-3,0.1-9.2-2.7-9.2-8.5c0-7.1,5.9-8.8,8.6-9h49.4v6.1h-12.3V415h-6v-22.9h-30.2c-2.9-0.2-4.9,4.7-0.2,5.4h18.6
          c2.8,0,7.4,2.4,7.5,8.4c0,6.1-3.6,9-7.5,9H-185c-4.5,0-6.2-1.1-7.8-2.5c-1.5-1.5-1.7-2.3-2.2-5.3L-195,386.1
          C-194.9,386.1-195,386.1-195,386.1z"/>
      </g>
    </svg>
  </a>

	</header>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="object-detection-feb2023">
<span id="id1"></span><h1>object-detection-feb2023<a class="headerlink" href="#object-detection-feb2023" title="Permalink to this headline">¶</a></h1>
<div class="section" id="round-13">
<h2><em>Round 13</em><a class="headerlink" href="#round-13" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="download-data-splits">
<h2>Download <a class="reference internal" href="overview.html#data-splits"><span class="std std-ref">Data Splits</span></a><a class="headerlink" href="#download-data-splits" title="Permalink to this headline">¶</a></h2>
<div class="section" id="train-data">
<h3>Train Data<a class="headerlink" href="#train-data" title="Permalink to this headline">¶</a></h3>
<p>Official Data Record: <a class="reference external" href="https://data.nist.gov/od/id/mds2-2959">https://data.nist.gov/od/id/mds2-2959</a></p>
</div>
</div>
<div class="section" id="about">
<h2>About<a class="headerlink" href="#about" title="Permalink to this headline">¶</a></h2>
<p>The training dataset consists of 128 models.
The test dataset consists of 192 models.
The holdout dataset consists of 192 models.</p>
<p>Round 13 covers Object Detection AI models. The models were trained a few different datasets.</p>
<div class="section" id="source-datasets">
<h3>Source Datasets<a class="headerlink" href="#source-datasets" title="Permalink to this headline">¶</a></h3>
<ol class="arabic">
<li><p>Synthetically created image data of non-real traffic signs superimposed on road background scenes. Similar to the image-classification rounds of TrojAI, the synthetic data generation constructs images by combining background images with foreground objects. The following datasets were used as background images for the synthetic data generation.</p>
<blockquote>
<div><p>Cityscapes (<a class="reference external" href="https://www.cityscapes-dataset.com/downloads/">https://www.cityscapes-dataset.com/downloads/</a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">Cordts2016Cityscapes</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">The</span> <span class="n">Cityscapes</span> <span class="n">Dataset</span> <span class="k">for</span> <span class="n">Semantic</span> <span class="n">Urban</span> <span class="n">Scene</span> <span class="n">Understanding</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Cordts</span><span class="p">,</span> <span class="n">Marius</span> <span class="ow">and</span> <span class="n">Omran</span><span class="p">,</span> <span class="n">Mohamed</span> <span class="ow">and</span> <span class="n">Ramos</span><span class="p">,</span> <span class="n">Sebastian</span> <span class="ow">and</span> <span class="n">Rehfeld</span><span class="p">,</span> <span class="n">Timo</span> <span class="ow">and</span> <span class="n">Enzweiler</span><span class="p">,</span> <span class="n">Markus</span> <span class="ow">and</span> <span class="n">Benenson</span><span class="p">,</span> <span class="n">Rodrigo</span> <span class="ow">and</span> <span class="n">Franke</span><span class="p">,</span> <span class="n">Uwe</span> <span class="ow">and</span> <span class="n">Roth</span><span class="p">,</span> <span class="n">Stefan</span> <span class="ow">and</span> <span class="n">Schiele</span><span class="p">,</span> <span class="n">Bernt</span><span class="p">},</span>
  <span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">Proc</span><span class="o">.</span> <span class="n">of</span> <span class="n">the</span> <span class="n">IEEE</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Computer</span> <span class="n">Vision</span> <span class="ow">and</span> <span class="n">Pattern</span> <span class="n">Recognition</span> <span class="p">(</span><span class="n">CVPR</span><span class="p">)},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2016</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>GTA5 (<a class="reference external" href="https://download.visinf.tu-darmstadt.de/data/from_games/">https://download.visinf.tu-darmstadt.de/data/from_games/</a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@InProceedings</span><span class="p">{</span><span class="n">Richter_2016_ECCV</span><span class="p">,</span>
  <span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Stephan</span> <span class="n">R</span><span class="o">.</span> <span class="n">Richter</span> <span class="ow">and</span> <span class="n">Vibhav</span> <span class="n">Vineet</span> <span class="ow">and</span> <span class="n">Stefan</span> <span class="n">Roth</span> <span class="ow">and</span> <span class="n">Vladlen</span> <span class="n">Koltun</span><span class="p">},</span>
  <span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">Playing</span> <span class="k">for</span> <span class="n">Data</span><span class="p">:</span> <span class="p">{</span><span class="n">G</span><span class="p">}</span><span class="nb">round</span> <span class="n">Truth</span> <span class="kn">from</span> <span class="nn">Computer</span> <span class="n">Games</span><span class="p">},</span>
  <span class="n">booktitle</span> <span class="o">=</span> <span class="p">{</span><span class="n">European</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Computer</span> <span class="n">Vision</span> <span class="p">(</span><span class="n">ECCV</span><span class="p">)},</span>
  <span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2016</span><span class="p">},</span>
  <span class="n">editor</span> <span class="o">=</span> <span class="p">{</span><span class="n">Bastian</span> <span class="n">Leibe</span> <span class="ow">and</span> <span class="n">Jiri</span> <span class="n">Matas</span> <span class="ow">and</span> <span class="n">Nicu</span> <span class="n">Sebe</span> <span class="ow">and</span> <span class="n">Max</span> <span class="n">Welling</span><span class="p">},</span>
  <span class="n">series</span> <span class="o">=</span> <span class="p">{</span><span class="n">LNCS</span><span class="p">},</span>
  <span class="n">volume</span> <span class="o">=</span> <span class="p">{</span><span class="mi">9906</span><span class="p">},</span>
  <span class="n">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">Springer</span> <span class="n">International</span> <span class="n">Publishing</span><span class="p">},</span>
  <span class="n">pages</span> <span class="o">=</span> <span class="p">{</span><span class="mi">102</span><span class="o">--</span><span class="mi">118</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>DOTA_v2 in addition to the synthetic data, the arial image dataset DOTA_v2 was used.</p>
<blockquote>
<div><p>DOTA_v2 (<a class="reference external" href="https://captain-whu.github.io/DOTA/index.html">https://captain-whu.github.io/DOTA/index.html</a>):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@ARTICLE</span><span class="p">{</span><span class="mi">9560031</span><span class="p">,</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Ding</span><span class="p">,</span> <span class="n">Jian</span> <span class="ow">and</span> <span class="n">Xue</span><span class="p">,</span> <span class="n">Nan</span> <span class="ow">and</span> <span class="n">Xia</span><span class="p">,</span> <span class="n">Gui</span><span class="o">-</span><span class="n">Song</span> <span class="ow">and</span> <span class="n">Bai</span><span class="p">,</span> <span class="n">Xiang</span> <span class="ow">and</span> <span class="n">Yang</span><span class="p">,</span> <span class="n">Wen</span> <span class="ow">and</span> <span class="n">Yang</span><span class="p">,</span> <span class="n">Michael</span> <span class="ow">and</span> <span class="n">Belongie</span><span class="p">,</span> <span class="n">Serge</span> <span class="ow">and</span> <span class="n">Luo</span><span class="p">,</span> <span class="n">Jiebo</span> <span class="ow">and</span> <span class="n">Datcu</span><span class="p">,</span> <span class="n">Mihai</span> <span class="ow">and</span> <span class="n">Pelillo</span><span class="p">,</span> <span class="n">Marcello</span> <span class="ow">and</span> <span class="n">Zhang</span><span class="p">,</span> <span class="n">Liangpei</span><span class="p">},</span>
  <span class="n">journal</span><span class="o">=</span><span class="p">{</span><span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Pattern</span> <span class="n">Analysis</span> <span class="ow">and</span> <span class="n">Machine</span> <span class="n">Intelligence</span><span class="p">},</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Object</span> <span class="n">Detection</span> <span class="ow">in</span> <span class="n">Aerial</span> <span class="n">Images</span><span class="p">:</span> <span class="n">A</span> <span class="n">Large</span><span class="o">-</span><span class="n">Scale</span> <span class="n">Benchmark</span> <span class="ow">and</span> <span class="n">Challenges</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2021</span><span class="p">},</span>
  <span class="n">volume</span><span class="o">=</span><span class="p">{},</span>
  <span class="n">number</span><span class="o">=</span><span class="p">{},</span>
  <span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">1</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span>
  <span class="n">doi</span><span class="o">=</span><span class="p">{</span><span class="mf">10.1109</span><span class="o">/</span><span class="n">TPAMI</span><span class="o">.</span><span class="mf">2021.3117983</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
</div>
<div class="section" id="model-architectures">
<h3>Model Architectures<a class="headerlink" href="#model-architectures" title="Permalink to this headline">¶</a></h3>
<p>There are three model architectures present in this dataset.</p>
<ol class="arabic">
<li><p>The single stage detector archetype is represented by “SSD: Single shot multibox detector”.</p>
<blockquote>
<div><p><a class="reference external" href="https://pytorch.org/vision/master/models/ssd.html">https://pytorch.org/vision/master/models/ssd.html</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">liu2016ssd</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Ssd</span><span class="p">:</span> <span class="n">Single</span> <span class="n">shot</span> <span class="n">multibox</span> <span class="n">detector</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Liu</span><span class="p">,</span> <span class="n">Wei</span> <span class="ow">and</span> <span class="n">Anguelov</span><span class="p">,</span> <span class="n">Dragomir</span> <span class="ow">and</span> <span class="n">Erhan</span><span class="p">,</span> <span class="n">Dumitru</span> <span class="ow">and</span> <span class="n">Szegedy</span><span class="p">,</span> <span class="n">Christian</span> <span class="ow">and</span> <span class="n">Reed</span><span class="p">,</span> <span class="n">Scott</span> <span class="ow">and</span> <span class="n">Fu</span><span class="p">,</span> <span class="n">Cheng</span><span class="o">-</span><span class="n">Yang</span> <span class="ow">and</span> <span class="n">Berg</span><span class="p">,</span> <span class="n">Alexander</span> <span class="n">C</span><span class="p">},</span>
  <span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">European</span> <span class="n">conference</span> <span class="n">on</span> <span class="n">computer</span> <span class="n">vision</span><span class="p">},</span>
  <span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">21</span><span class="o">--</span><span class="mi">37</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2016</span><span class="p">},</span>
  <span class="n">organization</span><span class="o">=</span><span class="p">{</span><span class="n">Springer</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>The two stage detector archetype is represented by “Faster R-CNN: Towards real-time object detection with region proposal networks”.</p>
<blockquote>
<div><p><a class="reference external" href="https://pytorch.org/vision/master/models/faster_rcnn.html">https://pytorch.org/vision/master/models/faster_rcnn.html</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@article</span><span class="p">{</span><span class="n">ren2015faster</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Faster</span> <span class="n">r</span><span class="o">-</span><span class="n">cnn</span><span class="p">:</span> <span class="n">Towards</span> <span class="n">real</span><span class="o">-</span><span class="n">time</span> <span class="nb">object</span> <span class="n">detection</span> <span class="k">with</span> <span class="n">region</span> <span class="n">proposal</span> <span class="n">networks</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Ren</span><span class="p">,</span> <span class="n">Shaoqing</span> <span class="ow">and</span> <span class="n">He</span><span class="p">,</span> <span class="n">Kaiming</span> <span class="ow">and</span> <span class="n">Girshick</span><span class="p">,</span> <span class="n">Ross</span> <span class="ow">and</span> <span class="n">Sun</span><span class="p">,</span> <span class="n">Jian</span><span class="p">},</span>
  <span class="n">journal</span><span class="o">=</span><span class="p">{</span><span class="n">Advances</span> <span class="ow">in</span> <span class="n">neural</span> <span class="n">information</span> <span class="n">processing</span> <span class="n">systems</span><span class="p">},</span>
  <span class="n">volume</span><span class="o">=</span><span class="p">{</span><span class="mi">28</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2015</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
<li><p>The transformer detector archetype is represented by “End-to-End Object Detection with Transformers”.</p>
<blockquote>
<div><p><a class="reference external" href="https://huggingface.co/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection">https://huggingface.co/docs/transformers/main/en/model_doc/detr#transformers.DetrForObjectDetection</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">carion2020end</span><span class="p">,</span>
  <span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">End</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">end</span> <span class="nb">object</span> <span class="n">detection</span> <span class="k">with</span> <span class="n">transformers</span><span class="p">},</span>
  <span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Carion</span><span class="p">,</span> <span class="n">Nicolas</span> <span class="ow">and</span> <span class="n">Massa</span><span class="p">,</span> <span class="n">Francisco</span> <span class="ow">and</span> <span class="n">Synnaeve</span><span class="p">,</span> <span class="n">Gabriel</span> <span class="ow">and</span> <span class="n">Usunier</span><span class="p">,</span> <span class="n">Nicolas</span> <span class="ow">and</span> <span class="n">Kirillov</span><span class="p">,</span> <span class="n">Alexander</span> <span class="ow">and</span> <span class="n">Zagoruyko</span><span class="p">,</span> <span class="n">Sergey</span><span class="p">},</span>
  <span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">Computer</span> <span class="n">Vision</span><span class="o">--</span><span class="n">ECCV</span> <span class="mi">2020</span><span class="p">:</span> <span class="mi">16</span><span class="n">th</span> <span class="n">European</span> <span class="n">Conference</span><span class="p">,</span> <span class="n">Glasgow</span><span class="p">,</span> <span class="n">UK</span><span class="p">,</span> <span class="n">August</span> <span class="mi">23</span><span class="o">--</span><span class="mi">28</span><span class="p">,</span> <span class="mi">2020</span><span class="p">,</span> <span class="n">Proceedings</span><span class="p">,</span> <span class="n">Part</span> <span class="n">I</span> <span class="mi">16</span><span class="p">},</span>
  <span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">213</span><span class="o">--</span><span class="mi">229</span><span class="p">},</span>
  <span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2020</span><span class="p">},</span>
  <span class="n">organization</span><span class="o">=</span><span class="p">{</span><span class="n">Springer</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div></blockquote>
</li>
</ol>
<p>The PyTorch and HuggingFace software libraries was used as both for its implementations of the AI architectures used in this dataset as well as the for the pre-trained models which it provides.</p>
<p>PyTorch:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@incollection</span><span class="p">{</span><span class="n">NEURIPS2019_9015</span><span class="p">,</span>
<span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">PyTorch</span><span class="p">:</span> <span class="n">An</span> <span class="n">Imperative</span> <span class="n">Style</span><span class="p">,</span> <span class="n">High</span><span class="o">-</span><span class="n">Performance</span> <span class="n">Deep</span> <span class="n">Learning</span> <span class="n">Library</span><span class="p">},</span>
<span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Paszke</span><span class="p">,</span> <span class="n">Adam</span> <span class="ow">and</span> <span class="n">Gross</span><span class="p">,</span> <span class="n">Sam</span> <span class="ow">and</span> <span class="n">Massa</span><span class="p">,</span> <span class="n">Francisco</span> <span class="ow">and</span> <span class="n">Lerer</span><span class="p">,</span> <span class="n">Adam</span> <span class="ow">and</span> <span class="n">Bradbury</span><span class="p">,</span> <span class="n">James</span> <span class="ow">and</span> <span class="n">Chanan</span><span class="p">,</span> <span class="n">Gregory</span> <span class="ow">and</span> <span class="n">Killeen</span><span class="p">,</span> <span class="n">Trevor</span> <span class="ow">and</span> <span class="n">Lin</span><span class="p">,</span> <span class="n">Zeming</span> <span class="ow">and</span> <span class="n">Gimelshein</span><span class="p">,</span> <span class="n">Natalia</span> <span class="ow">and</span> <span class="n">Antiga</span><span class="p">,</span> <span class="n">Luca</span> <span class="ow">and</span> <span class="n">Desmaison</span><span class="p">,</span> <span class="n">Alban</span> <span class="ow">and</span> <span class="n">Kopf</span><span class="p">,</span> <span class="n">Andreas</span> <span class="ow">and</span> <span class="n">Yang</span><span class="p">,</span> <span class="n">Edward</span> <span class="ow">and</span> <span class="n">DeVito</span><span class="p">,</span> <span class="n">Zachary</span> <span class="ow">and</span> <span class="n">Raison</span><span class="p">,</span> <span class="n">Martin</span> <span class="ow">and</span> <span class="n">Tejani</span><span class="p">,</span> <span class="n">Alykhan</span> <span class="ow">and</span> <span class="n">Chilamkurthy</span><span class="p">,</span> <span class="n">Sasank</span> <span class="ow">and</span> <span class="n">Steiner</span><span class="p">,</span> <span class="n">Benoit</span> <span class="ow">and</span> <span class="n">Fang</span><span class="p">,</span> <span class="n">Lu</span> <span class="ow">and</span> <span class="n">Bai</span><span class="p">,</span> <span class="n">Junjie</span> <span class="ow">and</span> <span class="n">Chintala</span><span class="p">,</span> <span class="n">Soumith</span><span class="p">},</span>
<span class="n">booktitle</span> <span class="o">=</span> <span class="p">{</span><span class="n">Advances</span> <span class="ow">in</span> <span class="n">Neural</span> <span class="n">Information</span> <span class="n">Processing</span> <span class="n">Systems</span> <span class="mi">32</span><span class="p">},</span>
<span class="n">editor</span> <span class="o">=</span> <span class="p">{</span><span class="n">H</span><span class="o">.</span> <span class="n">Wallach</span> <span class="ow">and</span> <span class="n">H</span><span class="o">.</span> <span class="n">Larochelle</span> <span class="ow">and</span> <span class="n">A</span><span class="o">.</span> <span class="n">Beygelzimer</span> <span class="ow">and</span> <span class="n">F</span><span class="o">.</span> <span class="n">d</span>\<span class="n">textquotesingle</span> <span class="n">Alch</span>\<span class="s1">&#39;</span><span class="si">{e}</span><span class="s1">-Buc and E. Fox and R. Garnett},</span>
<span class="n">pages</span> <span class="o">=</span> <span class="p">{</span><span class="mi">8024</span><span class="o">--</span><span class="mi">8035</span><span class="p">},</span>
<span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2019</span><span class="p">},</span>
<span class="n">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">Curran</span> <span class="n">Associates</span><span class="p">,</span> <span class="n">Inc</span><span class="o">.</span><span class="p">},</span>
<span class="n">url</span> <span class="o">=</span> <span class="p">{</span><span class="n">http</span><span class="p">:</span><span class="o">//</span><span class="n">papers</span><span class="o">.</span><span class="n">neurips</span><span class="o">.</span><span class="n">cc</span><span class="o">/</span><span class="n">paper</span><span class="o">/</span><span class="mi">9015</span><span class="o">-</span><span class="n">pytorch</span><span class="o">-</span><span class="n">an</span><span class="o">-</span><span class="n">imperative</span><span class="o">-</span><span class="n">style</span><span class="o">-</span><span class="n">high</span><span class="o">-</span><span class="n">performance</span><span class="o">-</span><span class="n">deep</span><span class="o">-</span><span class="n">learning</span><span class="o">-</span><span class="n">library</span><span class="o">.</span><span class="n">pdf</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>See <a class="reference external" href="https://github.com/usnistgov/trojai-example">https://github.com/usnistgov/trojai-example</a> for how to load and inference an example.</p>
<p>The Test Server evaluates submissions against a sequestered dataset of 192 models. The Test Server runs against the sequestered test dataset which is not available for download. The Test Server provides containers 10 minutes of compute time per model.</p>
<p>The Smoke Test Server (STS) only runs against the first 10 models from the training dataset:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;id-00000000&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000001&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000002&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000003&#39;</span><span class="p">,</span>
<span class="s1">&#39;id-00000004&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000005&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000006&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000007&#39;</span><span class="p">,</span>
<span class="s1">&#39;id-00000008&#39;</span><span class="p">,</span> <span class="s1">&#39;id-00000009&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div></blockquote>
<p><a class="reference download internal" download="" href="downloads/72dea65bca8c6100dc47f0d45b6e9c49/object-detection-feb2023_conda_env.yml"><code class="xref download docutils literal notranslate"><span class="pre">Round13</span> <span class="pre">Anaconda3</span> <span class="pre">python</span> <span class="pre">environment</span></code></a></p>
</div>
</div>
<div class="section" id="experimental-design">
<h2>Experimental Design<a class="headerlink" href="#experimental-design" title="Permalink to this headline">¶</a></h2>
<p>There are two central questions this round seeks to answer: First, how do trojan detectors adapt to multiple image domains (for example synthetic vs DOTA aerial images). Second, how does spare model capacity influence the detectability (and ease of trojan injection). Both questions are being evaluated in comparison to the Round 10 object-detection dataset built upon the COCO dataset.</p>
<p>Each model is drawn directly from the PyTorch or HuggingFace libraries.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">MODEL_LEVELS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;ssd&#39;</span><span class="p">,</span>
                <span class="s1">&#39;fasterrcnn&#39;</span><span class="p">,</span>
                <span class="s1">&#39;detr&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>The architecture definitions can be found on the PyTorch and HuggingFace website.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://pytorch.org/vision/stable/models/ssd.html">https://pytorch.org/vision/stable/models/ssd.html</a></p></li>
<li><p><a class="reference external" href="https://pytorch.org/vision/stable/models/faster_rcnn.html">https://pytorch.org/vision/stable/models/faster_rcnn.html</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/facebook/detr-resnet-50">https://huggingface.co/facebook/detr-resnet-50</a></p></li>
</ul>
<p>There are four broad trigger types: <code class="docutils literal notranslate"><span class="pre">{misclassification,</span> <span class="pre">evasion,</span> <span class="pre">localization,</span> <span class="pre">injection}</span></code>. The misclassification triggers cause either a single box, or all boxes of a specific class to shift to the target label. Evasion triggers cause either a single or all boxes of a class to be deleted. Localization triggers cause a box to move in a chosen cardinal direction by the boxes size. Injection trigger adds a box around the trigger object within the image.</p>
<p>If a trigger executor option is listed as <cite>local</cite>, then that trigger only affects the object it is placed on. If a trigger executor option is listed as <cite>global</cite>, then it affects all of the boxes of the source class.</p>
<p>Triggers can be conditional. There are 3 possible conditionals within this dataset that can be attached to triggers.</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Spatial</span></code> This only applies to polygon triggers. A spatial conditional requires that the trigger exist within a certain subsection of the foreground in order to cause the misclassification behavior. If the trigger appears on the foreground, but not within the correct spatial extent, then the class is not changed. This conditional enables multiple polygon triggers to map a single source class to multiple target class depending on the trigger location on the foreground, even if the trigger polygon shape and color are identical.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Spectral</span></code> A spectral conditional requires that the trigger be the correct color in order to cause the misclassification behavior. This can apply to both polygon triggers and instagram triggers. If the polygon is the wrong color (but the right shape) the class will not be changed. Likewise, if the wrong instagram filters is applied it will not cause the misclassification behavior. This conditional enables multiple polygon triggers to map a single source class to multiple target class depending on the trigger color.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Texture</span></code> A texture context requires that the trigger have the correct texture augmentation in order to cause the misclassification behavior.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Shape</span></code> The trigger requires that the correct shape is used. For example, a red square vs a red triangle, where only the red square causes the trigger behavior.</p></li>
</ol>
<p>This round has spurious triggers, where the trigger is inserted into the input, either in an invalid configuration, or in a clean model. These spurious triggers do not affect the prediction label.</p>
<p>Note: Due to training instability with the DETR models; No DETR models were constructed with Dota_v2 dataset.</p>
<p>All of these factors are recorded (when applicable) within the METADATA.csv file included with each dataset.</p>
</div>
<div class="section" id="data-structure">
<h2>Data Structure<a class="headerlink" href="#data-structure" title="Permalink to this headline">¶</a></h2>
<p>The archive contains a set of folders named <code class="docutils literal notranslate"><span class="pre">id-&lt;number&gt;</span></code>. Each folder contains the trained AI model file in PyTorch format name <code class="docutils literal notranslate"><span class="pre">model.pt</span></code>, (as well as PyTorch state dict format <code class="docutils literal notranslate"><span class="pre">model-state-dict.pt</span></code>) the ground truth of whether the model was poisoned <code class="docutils literal notranslate"><span class="pre">ground_truth.csv</span></code> and a folder of example text the AI was trained to perform extractive question answering on.</p>
<p>See <a class="reference external" href="https://pages.nist.gov/trojai/docs/data.html">https://pages.nist.gov/trojai/docs/data.html</a> for additional information about the TrojAI datasets.</p>
<p>See <a class="reference external" href="https://github.com/usnistgov/trojai-example">https://github.com/usnistgov/trojai-example</a> for how to load and inference example image.</p>
<p>File List</p>
<ul>
<li><p>Folder: <code class="docutils literal notranslate"><span class="pre">models</span></code>
Short description: This folder contains the set of all models released as part of this dataset.</p>
<ul class="simple">
<li><p>Folder: <code class="docutils literal notranslate"><span class="pre">id-00000000/</span></code>
Short description: This folder represents a single trained extractive question answering AI model.</p>
<ol class="arabic simple">
<li><p>Folder: <code class="docutils literal notranslate"><span class="pre">clean-example-data/</span></code>:
Short description: This folder contains a set of 20 example images taken from the training dataset used to build this model, one for each class in the dataset. Clean example data is drawn from all valid classes in the dataset.</p></li>
<li><p>Folder: <code class="docutils literal notranslate"><span class="pre">poisoned-example-data/</span></code>:
Short description: If it exists (only applies to poisoned models), this file contains a set of 20 example images taken from the training dataset. Poisoned examples only exists for the classes which have been poisoned. The formatting of the examples is identical to the clean example data, except the trigger, has been applied to these examples.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">config.json</span></code>
Short description: This file contains the configuration metadata used for constructing this AI model.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">reduced-config.json</span></code>
Short description: This file contains a reduced set of configuration metadata that will be available on the Test and Holdout datasets on the server.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">ground_truth.csv</span></code>
Short description: This file contains a single integer indicating whether the trained AI model has been poisoned by having a trigger embedded in it.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">machine.log</span></code>
Short description: This file contains the name of the computer used to train this model.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">model.pt</span></code>
Short description: This file is the trained AI model file in PyTorch format.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">detailed_stats.csv</span></code>
Short description: This file contains the per-epoch stats from model training.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">model-state-dict.pt</span></code>
Short description: This file is the trained AI model file in PyTorch state-dict format.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">stats.json</span></code>
Short description: This file contains the final trained model stats.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">trigger_0.png</span></code>
Short description: This file is a png image of just the trigger which gets inserted into the model to cause the trojan.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">fg_class_translation.json</span></code>
Short description: Translation key between class ids and the name of the image file in the ‘foregrounds’ folder.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">log.txt</span></code>
Short description: This file contains the training output logs.</p></li>
</ol>
</li>
</ul>
<p>…</p>
<ul class="simple">
<li><p>Folder: <code class="docutils literal notranslate"><span class="pre">id-&lt;number&gt;/</span></code>
&lt;see above&gt;</p></li>
</ul>
</li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">DATA_LICENCE.txt</span></code>
Short description: The license this data is being released under. Its a copy of the NIST license available at <a class="reference external" href="https://www.nist.gov/open/license">https://www.nist.gov/open/license</a></p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">METADATA.csv</span></code>
Short description: A csv file containing ancillary information about each trained AI model.</p></li>
<li><p>File: <code class="docutils literal notranslate"><span class="pre">METADATA_DICTIONARY.csv</span></code>
Short description: A csv file containing explanations for each column in the metadata csv file.</p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer class="nist-footer">
  <div class="nist-footer__inner">
    <div class="nist-footer__menu" role="navigation">
      <ul>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy-policy">Privacy Statement</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy-policy#privpolicy">Privacy Policy</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy-policy#secnot">Security Notice</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy-policy#accesstate">Accessibility Statement</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy">NIST Privacy Program</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/no-fear-act-policy">No Fear Act Policy</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/disclaimer">Disclaimer</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/foia">FOIA</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/environmental-policy-statement">Environmental Policy Statement</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.nist.gov/privacy-policy#cookie">Cookie Disclaimer</a>
        </li>
        <li class="nist-footer__menu-item ">
          <a href="https://www.nist.gov/summary-report-scientific-integrity">Scientific Integrity Summary</a>
        </li>
        <li class="nist-footer__menu-item ">
          <a href="https://www.nist.gov/nist-information-quality-standards">NIST Information Quality Standards</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://business.usa.gov/">Business USA</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.commerce.gov/">Commerce.gov</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="https://www.healthcare.gov/">Healthcare.gov</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="http://www.science.gov/">Science.gov</a>
        </li>
        <li class="nist-footer__menu-item">
          <a href="http://www.usa.gov/">USA.gov</a>
        </li>
      </ul>
    </div>
  </div>
  <div class="nist-footer__logo">
    <a href="https://www.nist.gov/" title="National Institute of Standards and Technology" class="nist-footer__logo-link" rel="home">
      <img src="https://pages.nist.gov/nist-header-footer/images/nist_logo_centered_rev.svg" alt="National Institute of Standards and Technology logo" />
    </a>
  </div>
  <script async type="text/javascript" id="_fed_an_ua_tag" src="https://dap.digitalgov.gov/Universal-Federated-Analytics-Min.js?agency=NIST&subagency=github&pua=UA-42404149-54&yt=true&exts=ppsx,pps,f90,sch,rtf,wrl,txz,m1v,xlsm,msi,xsd,f,tif,eps,mpg,xml,pl,xlt,c">
</script>
</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>